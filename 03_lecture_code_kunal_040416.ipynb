{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Databases via Web APIs: Lecture Code\n",
    "* * * * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import requests\n",
    "# from urllib3 import quote_plus\n",
    "import json\n",
    "from __future__ import division\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Constructing API GET Request\n",
    "\n",
    "In the first place, we know that every call will require us to provide a) a base URL for the API, b) some authorization code or key, and c) a format for the response. So let's put store those in some variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set key\n",
    "key=\"6e23901ee0fc07f0f6cee3a45b566bc5:13:73313103\"\n",
    "\n",
    "# set base url\n",
    "base_url=\"http://api.nytimes.com/svc/search/v2/articlesearch\"\n",
    "\n",
    "# set response format\n",
    "response_format=\".json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You often want to send some sort of data in the URL’s query string. This data tells the API what information you want. In our case, we want articles about Duke Ellington. Requests allows you to provide these arguments as a dictionary, using the `params` keyword argument. In addition to the search term `q`, we have to put in the `api-key` term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set search parameters\n",
    "search_params = {\"q\":\"Duke Ellington\",\n",
    "                 \"api-key\":key}       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to make the request. We use the `.get` method from the `requests` library to make an HTTP GET Request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make request\n",
    "r = requests.get(base_url+response_format, params=search_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a [response](http://docs.python-requests.org/en/latest/api/#requests.Response) object called `r`. We can get all the information we need from this object. For instance, we can see that the URL has been correctly encoded by printing the URL. Click on the link to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=6e23901ee0fc07f0f6cee3a45b566bc5%3A13%3A73313103&q=Duke+Ellington\n"
     ]
    }
   ],
   "source": [
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on that link to see it returns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1:  Adding a date range\n",
    "\n",
    "What if we only want to search within a particular date range? The NYT Article Api allows us to specify start and end dates.\n",
    "\n",
    "Alter the `search_params` code above so that the request only searches for articles in the year 2005.\n",
    "\n",
    "You're gonna need to look at the documentation [here](http://developer.nytimes.com/docs/read/article_search_api_v2) to see how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://api.nytimes.com/svc/search/v2/articlesearch.json?end_date=20051231&api-key=6e23901ee0fc07f0f6cee3a45b566bc5%3A13%3A73313103&q=Duke+Ellington&begin_date=20050101\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "\n",
    "search_params = {\"q\":\"Duke Ellington\",\n",
    "                 \"api-key\":key,\n",
    "                \"begin_date\": 20050101,\n",
    "                \"end_date\": 20051231,\n",
    "                }    \n",
    "# Uncomment to test\n",
    "r = requests.get(base_url+response_format, params=search_params)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2:  Specifying a results page\n",
    "\n",
    "The above will return the first 10 results. To get the next ten, you need to add a \"page\" parameter. Change the search parameters above to get the second 10 resuls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "# Uncomment to test\n",
    "# r = requests.get(base_url+response_format, params=search_params)\n",
    "# r.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parsing the response text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read the content of the server’s response using `.text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"response\":{\"meta\":{\"hits\":77,\"time\":36,\"offset\":0},\"docs\":[{\"web_url\":\"http:\\/\\/www.nytimes.com\\/2005\\/10\\/02\\/nyregion\\/02bookshelf.html\",\"snippet\":\"A WIDOW'S WALK:.\",\"lead_paragraph\":\"A WIDOW'S WALK: A Memoir of 9\\/11 By Marian Fontana Simon & Schuster ($24, hardcover) Theresa and I walk into the Blue Ribbon, an expensive, trendy restaurant on Fifth Avenue in Park Slope. We sit at a banquette in the middle of the room and read the eclectic menu, my eyes instinctively scanning the prices for the least expensive item.\",\"abstract\":null,\"print_page\":\"9\",\"blog\":[],\"source\":\"The New York Times\",\"multimedia\":[],\"headline\":{\"main\":\"NEW YORK BOOKSHELF\\/NONFICTION\",\"kicker\":\"New York Bookshelf\"},\"keywords\":[{\"name\":\"persons\",\"value\":\"ELLINGTON, DUKE\"},{\"name\":\"persons\",\"value\":\"HARRIS, DANIEL\"}],\"pub_date\":\"2005-10-02T00:00:00Z\",\"document_type\":\"article\",\"news_desk\":\"The City Weekly Desk\",\"section_name\":\"New York and Region\",\"subsection_name\":null,\"byline\":{\"person\":[{\"firstname\":\"N.\",\"middl\n"
     ]
    }
   ],
   "source": [
    "# Inspect the content of the response, parsing the result as text\n",
    "response_text= r.text\n",
    "print(response_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you see here is JSON text, encoded as unicode text. JSON stands for \"Javascript object notation.\" It has a very similar structure to a python dictionary -- both are built on key/value pairs. This makes it easy to convert JSON response to a python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert JSON response to a dictionary\n",
    "data=json.loads(response_text)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks intimidating! But it's really just a big dictionary. Let's see what keys we got in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['response', 'copyright', 'status'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OK'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is boring\n",
    "data['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Copyright (c) 2013 The New York Times Company.  All Rights Reserved.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so is this\n",
    "data['copyright']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is what we want!\n",
    "#data['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['meta', 'docs'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['response'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hits': 77, 'offset': 0, 'time': 36}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['response']['meta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data['response']['docs']\n",
    "type(data['response']['docs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks what we want! Let's put that in it's own variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs = data['response']['docs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '4fd2872b8eb7c8105d858553',\n",
       " 'abstract': None,\n",
       " 'blog': [],\n",
       " 'byline': {'original': 'By N.R. Kleinfield',\n",
       "  'person': [{'firstname': 'N.',\n",
       "    'lastname': 'Kleinfield',\n",
       "    'middlename': 'R.',\n",
       "    'organization': '',\n",
       "    'rank': 1,\n",
       "    'role': 'reported'}]},\n",
       " 'document_type': 'article',\n",
       " 'headline': {'kicker': 'New York Bookshelf',\n",
       "  'main': 'NEW YORK BOOKSHELF/NONFICTION'},\n",
       " 'keywords': [{'name': 'persons', 'value': 'ELLINGTON, DUKE'},\n",
       "  {'name': 'persons', 'value': 'HARRIS, DANIEL'}],\n",
       " 'lead_paragraph': \"A WIDOW'S WALK: A Memoir of 9/11 By Marian Fontana Simon & Schuster ($24, hardcover) Theresa and I walk into the Blue Ribbon, an expensive, trendy restaurant on Fifth Avenue in Park Slope. We sit at a banquette in the middle of the room and read the eclectic menu, my eyes instinctively scanning the prices for the least expensive item.\",\n",
       " 'multimedia': [],\n",
       " 'news_desk': 'The City Weekly Desk',\n",
       " 'print_page': '9',\n",
       " 'pub_date': '2005-10-02T00:00:00Z',\n",
       " 'section_name': 'New York and Region',\n",
       " 'slideshow_credits': None,\n",
       " 'snippet': \"A WIDOW'S WALK:.\",\n",
       " 'source': 'The New York Times',\n",
       " 'subsection_name': None,\n",
       " 'type_of_material': 'News',\n",
       " 'web_url': 'http://www.nytimes.com/2005/10/02/nyregion/02bookshelf.html',\n",
       " 'word_count': 629}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Putting everything together to get all the articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's great. But we only have 10 items. The original response said we had 171 hits! Which means we have to make 171 /10, or 18 requests to get them all. Sounds like a job for a loop! \n",
    "\n",
    "But first, let's review what we've done so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of hits: 77\n",
      "collecting page 0\n",
      "collecting page 1\n",
      "collecting page 2\n",
      "collecting page 3\n",
      "collecting page 4\n",
      "collecting page 5\n",
      "collecting page 6\n",
      "collecting page 7\n"
     ]
    }
   ],
   "source": [
    "# set key\n",
    "key=\"6e23901ee0fc07f0f6cee3a45b566bc5:13:73313103\"\n",
    "# set base url\n",
    "base_url=\"http://api.nytimes.com/svc/search/v2/articlesearch\"\n",
    "# set response format\n",
    "response_format=\".json\"\n",
    "# set search parameters\n",
    "search_params = {\"q\":\"Duke Ellington\",\n",
    "                 \"api-key\":key,\n",
    "                 \"begin_date\":\"20050101\", # date must be in YYYYMMDD format\n",
    "                 \"end_date\":\"20051231\"}\n",
    "# make request\n",
    "r = requests.get(base_url+response_format, params=search_params)\n",
    "# convert to a dictionary\n",
    "data=json.loads(r.text)\n",
    "# get number of hits\n",
    "hits = data['response']['meta']['hits']\n",
    "print(\"number of hits: \" + str(hits))\n",
    "# get number of pages\n",
    "pages = int(math.ceil(hits/10))\n",
    "# make an empty list where we'll hold all of our docs for every page\n",
    "all_docs = [] \n",
    "# now we're ready to loop through the pages\n",
    "for i in range(pages):\n",
    "    print(\"collecting page \" + str(i))\n",
    "    # set the page parameter\n",
    "    search_params['page'] = i\n",
    "    # make request\n",
    "    r = requests.get(base_url+response_format, params=search_params)\n",
    "    # get text and convert to a dictionary\n",
    "    data=json.loads(r.text)\n",
    "    # get just the docs\n",
    "    docs = data['response']['docs']\n",
    "    # add those docs to the big list\n",
    "    all_docs = all_docs + docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Make a function\n",
    "\n",
    "Turn the code above into a function that inputs a search term, and returns all the documents containing that search term in 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "def search_nyt_2014(term, year = 2014):\n",
    "    # set key\n",
    "    key=\"6e23901ee0fc07f0f6cee3a45b566bc5:13:73313103\"\n",
    "    # set base url\n",
    "    base_url=\"http://api.nytimes.com/svc/search/v2/articlesearch\"\n",
    "    # set response format\n",
    "    response_format=\".json\"\n",
    "    # set search parameters\n",
    "    search_params = {\"q\":term,\n",
    "                     \"api-key\":key,\n",
    "                     \"begin_date\":str(year)+\"0101\", # date must be in YYYYMMDD format\n",
    "                     \"end_date\":str(year)+\"1231\"}\n",
    "    # make request\n",
    "    r = requests.get(base_url+response_format, params=search_params)\n",
    "    # convert to a dictionary\n",
    "    data=json.loads(r.text)\n",
    "    # get number of hits\n",
    "    hits = data['response']['meta']['hits']\n",
    "    print(\"number of hits: \" + str(hits))\n",
    "    # get number of pages\n",
    "    pages = int(math.ceil(hits/10))\n",
    "    # make an empty list where we'll hold all of our docs for every page\n",
    "    all_docs = [] \n",
    "    # now we're ready to loop through the pages\n",
    "    for i in range(pages):\n",
    "        print(\"collecting page \" + str(i))\n",
    "        # set the page parameter\n",
    "        search_params['page'] = i\n",
    "        # make request\n",
    "        r = requests.get(base_url+response_format, params=search_params)\n",
    "        # get text and convert to a dictionary\n",
    "        data=json.loads(r.text)\n",
    "        # get just the docs\n",
    "        docs = data['response']['docs']\n",
    "        # add those docs to the big list\n",
    "        all_docs = all_docs + docs\n",
    "    return all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of hits: 572\n",
      "collecting page 0\n",
      "collecting page 1\n",
      "collecting page 2\n",
      "collecting page 3\n",
      "collecting page 4\n",
      "collecting page 5\n",
      "collecting page 6\n",
      "collecting page 7\n",
      "collecting page 8\n",
      "collecting page 9\n",
      "collecting page 10\n",
      "collecting page 11\n",
      "collecting page 12\n",
      "collecting page 13\n",
      "collecting page 14\n",
      "collecting page 15\n",
      "collecting page 16\n",
      "collecting page 17\n",
      "collecting page 18\n",
      "collecting page 19\n",
      "collecting page 20\n",
      "collecting page 21\n",
      "collecting page 22\n",
      "collecting page 23\n",
      "collecting page 24\n",
      "collecting page 25\n",
      "collecting page 26\n",
      "collecting page 27\n",
      "collecting page 28\n",
      "collecting page 29\n",
      "collecting page 30\n",
      "collecting page 31\n",
      "collecting page 32\n",
      "collecting page 33\n",
      "collecting page 34\n",
      "collecting page 35\n",
      "collecting page 36\n",
      "collecting page 37\n",
      "collecting page 38\n",
      "collecting page 39\n",
      "collecting page 40\n",
      "collecting page 41\n",
      "collecting page 42\n",
      "collecting page 43\n",
      "collecting page 44\n",
      "collecting page 45\n",
      "collecting page 46\n",
      "collecting page 47\n",
      "collecting page 48\n",
      "collecting page 49\n",
      "collecting page 50\n",
      "collecting page 51\n",
      "collecting page 52\n",
      "collecting page 53\n",
      "collecting page 54\n",
      "collecting page 55\n",
      "collecting page 56\n",
      "collecting page 57\n"
     ]
    }
   ],
   "source": [
    "stuff = search_nyt_2014(\"marco rubio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Formatting and Exporting\n",
    "\n",
    "Let's take another look at one of these documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '53755d9c79881068df7c36a4',\n",
       " 'abstract': \"Paul Krugman Op-Ed column criticizes Republican Sen Marco Rubio for declaring overwhelming scientific consensus on climate change to be false; contends Republicans have reached a point where allegiance to false doctrines has become crucial badge of identity; compares party's resistance to science about climate change to its insistence that runaway inflation is a problem.\",\n",
       " 'blog': [],\n",
       " 'byline': {'contributor': '',\n",
       "  'original': 'By PAUL KRUGMAN',\n",
       "  'person': [{'firstname': 'Paul',\n",
       "    'lastname': 'KRUGMAN',\n",
       "    'organization': '',\n",
       "    'rank': 1,\n",
       "    'role': 'reported'}]},\n",
       " 'document_type': 'article',\n",
       " 'headline': {'content_kicker': 'Op-Ed Columnist',\n",
       "  'kicker': 'Op-Ed Columnist',\n",
       "  'main': 'Points of No Return',\n",
       "  'print_headline': 'Points of No Return'},\n",
       " 'keywords': [{'is_major': 'Y',\n",
       "   'name': 'subject',\n",
       "   'rank': '1',\n",
       "   'value': 'Global Warming'},\n",
       "  {'is_major': 'Y',\n",
       "   'name': 'subject',\n",
       "   'rank': '2',\n",
       "   'value': 'United States Politics and Government'},\n",
       "  {'is_major': 'N',\n",
       "   'name': 'organizations',\n",
       "   'rank': '3',\n",
       "   'value': 'Republican Party'},\n",
       "  {'is_major': 'Y', 'name': 'persons', 'rank': '4', 'value': 'Rubio, Marco'},\n",
       "  {'is_major': 'Y',\n",
       "   'name': 'subject',\n",
       "   'rank': '5',\n",
       "   'value': 'Inflation (Economics)'},\n",
       "  {'is_major': 'N',\n",
       "   'name': 'glocations',\n",
       "   'rank': '6',\n",
       "   'value': 'United States'}],\n",
       " 'lead_paragraph': 'False doctrines on climate science have become badges of identity for Republicans, and that&#8217;s more frightening than some of the environmental change underway.',\n",
       " 'multimedia': [{'height': 126,\n",
       "   'legacy': {'wide': 'images/2014/10/30/opinion/krugman-new-1114/krugman-new-1114-thumbWide.jpg',\n",
       "    'wideheight': '126',\n",
       "    'widewidth': '190'},\n",
       "   'subtype': 'wide',\n",
       "   'type': 'image',\n",
       "   'url': 'images/2014/10/30/opinion/krugman-new-1114/krugman-new-1114-thumbWide.jpg',\n",
       "   'width': 190},\n",
       "  {'height': 900,\n",
       "   'legacy': {'xlarge': 'images/2014/10/30/opinion/krugman-new-1114/krugman-new-1114-articleLarge.jpg',\n",
       "    'xlargeheight': '900',\n",
       "    'xlargewidth': '600'},\n",
       "   'subtype': 'xlarge',\n",
       "   'type': 'image',\n",
       "   'url': 'images/2014/10/30/opinion/krugman-new-1114/krugman-new-1114-articleLarge.jpg',\n",
       "   'width': 600},\n",
       "  {'height': 75,\n",
       "   'legacy': {'thumbnail': 'images/2014/10/30/opinion/krugman-new-1114/krugman-new-1114-thumbStandard.jpg',\n",
       "    'thumbnailheight': '75',\n",
       "    'thumbnailwidth': '75'},\n",
       "   'subtype': 'thumbnail',\n",
       "   'type': 'image',\n",
       "   'url': 'images/2014/10/30/opinion/krugman-new-1114/krugman-new-1114-thumbStandard.jpg',\n",
       "   'width': 75}],\n",
       " 'news_desk': 'Editorial',\n",
       " 'print_page': '27',\n",
       " 'pub_date': '2014-05-16T00:00:00Z',\n",
       " 'section_name': 'Opinion',\n",
       " 'slideshow_credits': None,\n",
       " 'snippet': 'False doctrines on climate science have become badges of identity for Republicans, and that&#8217;s more frightening than some of the environmental change underway.',\n",
       " 'source': 'The New York Times',\n",
       " 'subsection_name': None,\n",
       " 'type_of_material': 'Op-Ed',\n",
       " 'web_url': 'http://www.nytimes.com/2014/05/16/opinion/krugman-points-of-no-return.html',\n",
       " 'word_count': '786'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all great, but it's pretty messy. What we’d really like to to have, eventually, is a CSV, with each row representing an article, and each column representing something about that article (header, date, etc). As we saw before, the best way to do this is to make a lsit of dictionaries, with each dictionary representing an article and each dictionary representing a field of metadata from that article (e.g. headline, date, etc.) We can do this with a custom function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_articles(unformatted_docs):\n",
    "    '''\n",
    "    This function takes in a list of documents returned by the NYT api \n",
    "    and parses the documents into a list of dictionaries, \n",
    "    with 'id', 'header', and 'date' keys\n",
    "    '''\n",
    "    formatted = []\n",
    "    for i in unformatted_docs:\n",
    "        dic = {}\n",
    "        dic['id'] = i['_id']\n",
    "        dic['headline'] = i['headline']['main'].encode(\"utf8\")\n",
    "        dic['date'] = i['pub_date'][0:10] # cutting time of day.\n",
    "        formatted.append(dic)\n",
    "    return(formatted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_formatted = format_articles(stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': '2014-05-16',\n",
       "  'headline': b'Points of No Return',\n",
       "  'id': '53755d9c79881068df7c36a4'},\n",
       " {'date': '2014-12-18',\n",
       "  'headline': b'2014: Rubio Criticizes Obama on Cuba',\n",
       "  'id': '5493863779881048d26b30e3'},\n",
       " {'date': '2014-11-11',\n",
       "  'headline': b'A Well-Timed Book Tour for Rubio',\n",
       "  'id': '5462503079881072f4f7304b'},\n",
       " {'date': '2014-05-12',\n",
       "  'headline': b'Rubio on a Presidential Bid, and Climate Change',\n",
       "  'id': '536fc5c2798810420b81d1ee'},\n",
       " {'date': '2014-03-02',\n",
       "  'headline': b'Rubio Proposes Steps U.S. Should Take With Russia',\n",
       "  'id': '531288fb79881022a8e2e718'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_formatted[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 4: Export the data to a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of hits: 87\n",
      "collecting page 0\n",
      "collecting page 1\n",
      "collecting page 2\n",
      "collecting page 3\n",
      "collecting page 4\n",
      "collecting page 5\n",
      "collecting page 6\n",
      "collecting page 7\n",
      "collecting page 8\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "stuff = search_nyt_2014(\"berkeley police california\", 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "testfile = open('test.csv','w')\n",
    "f = csv.writer(testfile)\n",
    "f.writerow([\"date\", \"headline\", \"id\"])\n",
    "for x in format_articles(stuff):\n",
    "    f.writerow([x[\"date\"],x[\"headline\"],x[\"id\"]])\n",
    "testfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
